{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2ZsV4YV4Z8fZJCwfgJ3ot",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wizkid254/data-cleansing.py/blob/main/Untitled0.ipynb%20machine%20learning\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ejpdtc-W9tVw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9482d8a"
      },
      "source": [
        "# Task\n",
        "Load and explore the dataset from `/content/cleaned_process_notes.xlsx`, then ask for more specific details regarding the machine learning task (e.g., classification, regression, clustering, target variable)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd48b13f"
      },
      "source": [
        "## Load Dataset\n",
        "\n",
        "### Subtask:\n",
        "Load the provided dataset from '/content/cleaned_process_notes.xlsx' into a pandas DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03361eab"
      },
      "source": [
        "**Reasoning**:\n",
        "To load the dataset, I need to import the pandas library and then use its `read_excel` function to load the specified Excel file into a DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23c4f482",
        "outputId": "43e83541-7b2d-40b5-b061-ecdd63a73a35"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel('/content/cleaned_process_notes.xlsx')\n",
        "print(\"DataFrame loaded successfully. First 5 rows:\")\n",
        "print(df.head())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame loaded successfully. First 5 rows:\n",
            "  Counsellor    Client        Session Date Session Duration        Phase  \\\n",
            "0    Daniele  VanessaM 2018-01-15 00:00:00       61-75 mins   Life Story   \n",
            "1    Daniele    GavinV 2018-01-23 00:00:00       46-60 mins       Step 5   \n",
            "2    Daniele     JeanS 2018-01-28 00:00:00       61-75 mins  Reflections   \n",
            "3       Mart     TianP 2018-02-13 14:55:00     106-120 mins       Step 1   \n",
            "4       Mart  BonganiM 2018-02-18 11:40:00       16-30 mins       Step 1   \n",
            "\n",
            "                                             Process  \\\n",
            "0  Honest and open account of her Life Story. Van...   \n",
            "1  Gavin has had a lot of extra time to invest in...   \n",
            "2  Jean presented one of the most detailed reflec...   \n",
            "3  \"Tian's step work started a lot in blocks of t...   \n",
            "4  Bongani has a clear concept about the disease ...   \n",
            "\n",
            "                                          Evaluation  \\\n",
            "0  Vanessa has been stuck in victim mode even pri...   \n",
            "1  There were a lot of negative emotions such as ...   \n",
            "2  The assignment was so detailed and comprehensi...   \n",
            "3  \"Tian is everywhere yet nowhere, but his answe...   \n",
            "4  Bongani shows a great willingness, openness an...   \n",
            "\n",
            "                                            Planning  \\\n",
            "0  Step 1 will be a revelation in terms of powerl...   \n",
            "1         Gavin to continue with step 6 and summary.   \n",
            "2  Completion and life story presentation to follow.   \n",
            "3  I told Tian to continue with his steps and ind...   \n",
            "4  Bongani will continue with his step work as pl...   \n",
            "\n",
            "   Session Duration Numeric  Process Word Count  Evaluation Word Count  \\\n",
            "0                        61                 116                    207   \n",
            "1                        46                  78                     98   \n",
            "2                        61                  75                    125   \n",
            "3                       106                 185                     97   \n",
            "4                        16                 215                     72   \n",
            "\n",
            "   Planning Word Count  \n",
            "0                   13  \n",
            "1                    8  \n",
            "2                    7  \n",
            "3                   27  \n",
            "4                    9  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "803ddf3d"
      },
      "source": [
        "## Explore Dataset\n",
        "\n",
        "### Subtask:\n",
        "Display basic information about the dataset, including its shape, columns, data types, and check for any missing values. This will help us understand the data characteristics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c561fcf5"
      },
      "source": [
        "**Reasoning**:\n",
        "To understand the dataset's basic characteristics, I will first print its shape to see the number of rows and columns, then display a concise summary to check data types and non-null values, and finally, calculate the sum of missing values per column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b129083",
        "outputId": "7d780e83-cb4c-41a7-bf8c-ea062e0e0a8f"
      },
      "source": [
        "print(\"DataFrame Shape:\", df.shape)\n",
        "print(\"\\nDataFrame Info:\")\n",
        "df.info()\n",
        "print(\"\\nMissing Values per Column:\")\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame Shape: (4475, 12)\n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4475 entries, 0 to 4474\n",
            "Data columns (total 12 columns):\n",
            " #   Column                    Non-Null Count  Dtype         \n",
            "---  ------                    --------------  -----         \n",
            " 0   Counsellor                4475 non-null   object        \n",
            " 1   Client                    4475 non-null   object        \n",
            " 2   Session Date              4475 non-null   datetime64[ns]\n",
            " 3   Session Duration          4475 non-null   object        \n",
            " 4   Phase                     4475 non-null   object        \n",
            " 5   Process                   4473 non-null   object        \n",
            " 6   Evaluation                4475 non-null   object        \n",
            " 7   Planning                  4475 non-null   object        \n",
            " 8   Session Duration Numeric  4475 non-null   int64         \n",
            " 9   Process Word Count        4475 non-null   int64         \n",
            " 10  Evaluation Word Count     4475 non-null   int64         \n",
            " 11  Planning Word Count       4475 non-null   int64         \n",
            "dtypes: datetime64[ns](1), int64(4), object(7)\n",
            "memory usage: 419.7+ KB\n",
            "\n",
            "Missing Values per Column:\n",
            "Counsellor                  0\n",
            "Client                      0\n",
            "Session Date                0\n",
            "Session Duration            0\n",
            "Phase                       0\n",
            "Process                     2\n",
            "Evaluation                  0\n",
            "Planning                    0\n",
            "Session Duration Numeric    0\n",
            "Process Word Count          0\n",
            "Evaluation Word Count       0\n",
            "Planning Word Count         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbf5de5f"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Review the dataset's characteristics and then ask the user for more specific details regarding the machine learning task they want to perform (e.g., classification, regression, clustering, target variable).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14675a42"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The dataset, loaded from `/content/cleaned_process_notes.xlsx`, contains 4475 rows and 12 columns.\n",
        "*   The columns include `Counsellor`, `Client`, `Session Date`, `Session Duration`, `Phase`, `Process`, `Evaluation`, `Planning`, and several word count/numeric columns.\n",
        "*   The data types are mixed, consisting of one `datetime64[ns]` column, four `int64` columns, and seven `object` columns.\n",
        "*   Most columns are complete; however, the 'Process' column has 2 missing values.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The dataset is ready for further analysis, but the 2 missing values in the 'Process' column should be addressed (e.g., imputation or removal) depending on the machine learning task.\n",
        "*   The next step is to ask the user for specific details about the desired machine learning task (e.g., classification, regression, clustering, target variable) to guide further preprocessing and model selection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61460854"
      },
      "source": [
        "# Task\n",
        "The notebook has loaded the dataset and performed an initial exploration. The next step is to perform a regression task. Please specify which numerical column from the dataset you would like to predict. You can choose from the following columns: 'Session Duration Numeric', 'Process Word Count', 'Evaluation Word Count', 'Planning Word Count'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70eee7d5"
      },
      "source": [
        "## Get Regression Target Variable\n",
        "\n",
        "### Subtask:\n",
        "Ask the user to specify which numerical column from the dataset they want to predict as the target variable for the regression task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60d943df"
      },
      "source": [
        "### Subtask:\n",
        "Ask the user to specify which numerical column from the dataset they want to predict as the target variable for the regression task.\n",
        "\n",
        "#### Instructions\n",
        "The notebook has loaded the dataset and performed an initial exploration. The next step is to perform a regression task. Please specify which numerical column from the dataset you would like to predict. You can choose from the following columns: 'Session Duration Numeric', 'Process Word Count', 'Evaluation Word Count', 'Planning Word Count'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b71db56"
      },
      "source": [
        "## Confirm Regression Target\n",
        "\n",
        "### Subtask:\n",
        "Select 'Session Duration Numeric' as the target variable for the regression task and confirm the machine learning objective.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HFcJ44cZCmLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b354afcf"
      },
      "source": [
        "### Target Variable Confirmation\n",
        "\n",
        "**Acknowledgement:** I understand the request to choose a numerical column as the target variable for a regression task.\n",
        "\n",
        "**Selection:** The column 'Session Duration Numeric' will be selected as the target variable for prediction.\n",
        "\n",
        "**Machine Learning Objective:** The objective is to perform a **regression task** to predict the numerical value of the 'Session Duration Numeric' column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd07b969"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Generate a new detailed plan for data preparation, model selection, and training based on the confirmed regression target variable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff3ee8fd"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The numerical column chosen for prediction is 'Session Duration Numeric'.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The available numerical columns for regression target selection were 'Session Duration Numeric', 'Process Word Count', 'Evaluation Word Count', and 'Planning Word Count'.\n",
        "*   'Session Duration Numeric' was explicitly selected as the target variable for the regression task.\n",
        "*   The machine learning objective was confirmed as performing a regression task to predict the numerical value of the 'Session Duration Numeric' column.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The next step involves generating a detailed plan for data preparation, model selection, and training, focusing on predicting 'Session Duration Numeric'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb1b5517"
      },
      "source": [
        "# Task\n",
        "Develop a regression model to predict 'Session Duration Numeric' using the dataset from `/content/cleaned_process_notes.xlsx`, which involves preprocessing the data, engineering features from text columns ('Process', 'Evaluation', and 'Planning') and categorical columns ('Counsellor', 'Client', 'Phase', 'Session Duration'), training a suitable regression model, and evaluating its performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "458d10b5"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "### Subtask:\n",
        "Handle missing values in the 'Process' column, confirm 'Session Date' is a datetime object, and encode categorical features ('Counsellor', 'Client', 'Phase', 'Session Duration').\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "924eb638"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I will address the missing values in the 'Process' column by filling the 2 NaN values with an empty string, as specified in the instructions. This is a common practice for text-based features when NaN values are present.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3df4f253",
        "outputId": "ebb5f3ea-0a8d-4bd6-cd1c-6a16f9772ec0"
      },
      "source": [
        "df['Process'] = df['Process'].fillna('')\n",
        "print(\"Missing values in 'Process' column after filling:\")\n",
        "print(df['Process'].isnull().sum())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in 'Process' column after filling:\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12b7caa5"
      },
      "source": [
        "**Reasoning**:\n",
        "Next, I will verify that the 'Session Date' column is already a datetime object, and then apply one-hot encoding to the specified categorical columns ('Counsellor', 'Client', 'Phase', 'Session Duration') to prepare them for model training, dropping the original columns to avoid redundancy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a9c23e5",
        "outputId": "6438febe-67d8-4e88-d65e-d872ec747405"
      },
      "source": [
        "print(\"Data type of 'Session Date' before verification:\", df['Session Date'].dtype)\n",
        "if not pd.api.types.is_datetime64_any_dtype(df['Session Date']):\n",
        "    df['Session Date'] = pd.to_datetime(df['Session Date'])\n",
        "    print(\"Converted 'Session Date' to datetime type.\")\n",
        "else:\n",
        "    print(\"'Session Date' is already of datetime type.\")\n",
        "\n",
        "categorical_cols = ['Counsellor', 'Client', 'Phase', 'Session Duration']\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "print(\"\\nShape of DataFrame after one-hot encoding:\", df_encoded.shape)\n",
        "print(\"First 5 rows of the DataFrame after one-hot encoding:\")\n",
        "print(df_encoded.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data type of 'Session Date' before verification: datetime64[ns]\n",
            "'Session Date' is already of datetime type.\n",
            "\n",
            "Shape of DataFrame after one-hot encoding: (4475, 494)\n",
            "First 5 rows of the DataFrame after one-hot encoding:\n",
            "         Session Date                                            Process  \\\n",
            "0 2018-01-15 00:00:00  Honest and open account of her Life Story. Van...   \n",
            "1 2018-01-23 00:00:00  Gavin has had a lot of extra time to invest in...   \n",
            "2 2018-01-28 00:00:00  Jean presented one of the most detailed reflec...   \n",
            "3 2018-02-13 14:55:00  \"Tian's step work started a lot in blocks of t...   \n",
            "4 2018-02-18 11:40:00  Bongani has a clear concept about the disease ...   \n",
            "\n",
            "                                          Evaluation  \\\n",
            "0  Vanessa has been stuck in victim mode even pri...   \n",
            "1  There were a lot of negative emotions such as ...   \n",
            "2  The assignment was so detailed and comprehensi...   \n",
            "3  \"Tian is everywhere yet nowhere, but his answe...   \n",
            "4  Bongani shows a great willingness, openness an...   \n",
            "\n",
            "                                            Planning  \\\n",
            "0  Step 1 will be a revelation in terms of powerl...   \n",
            "1         Gavin to continue with step 6 and summary.   \n",
            "2  Completion and life story presentation to follow.   \n",
            "3  I told Tian to continue with his steps and ind...   \n",
            "4  Bongani will continue with his step work as pl...   \n",
            "\n",
            "   Session Duration Numeric  Process Word Count  Evaluation Word Count  \\\n",
            "0                        61                 116                    207   \n",
            "1                        46                  78                     98   \n",
            "2                        61                  75                    125   \n",
            "3                       106                 185                     97   \n",
            "4                        16                 215                     72   \n",
            "\n",
            "   Planning Word Count  Counsellor_Daniele  Counsellor_Desmond  ...  \\\n",
            "0                   13                True               False  ...   \n",
            "1                    8                True               False  ...   \n",
            "2                    7                True               False  ...   \n",
            "3                   27               False               False  ...   \n",
            "4                    9               False               False  ...   \n",
            "\n",
            "   Session Duration_30 mins  Session Duration_31-45 mins  \\\n",
            "0                     False                        False   \n",
            "1                     False                        False   \n",
            "2                     False                        False   \n",
            "3                     False                        False   \n",
            "4                     False                        False   \n",
            "\n",
            "   Session Duration_40 mins  Session Duration_41 mins  \\\n",
            "0                     False                     False   \n",
            "1                     False                     False   \n",
            "2                     False                     False   \n",
            "3                     False                     False   \n",
            "4                     False                     False   \n",
            "\n",
            "   Session Duration_46-60 mins  Session Duration_61-75 mins  \\\n",
            "0                        False                         True   \n",
            "1                         True                        False   \n",
            "2                        False                         True   \n",
            "3                        False                        False   \n",
            "4                        False                        False   \n",
            "\n",
            "   Session Duration_75-90 mins  Session Duration_76-90 mins  \\\n",
            "0                        False                        False   \n",
            "1                        False                        False   \n",
            "2                        False                        False   \n",
            "3                        False                        False   \n",
            "4                        False                        False   \n",
            "\n",
            "   Session Duration_90 mins  Session Duration_91-105 mins  \n",
            "0                     False                         False  \n",
            "1                     False                         False  \n",
            "2                     False                         False  \n",
            "3                     False                         False  \n",
            "4                     False                         False  \n",
            "\n",
            "[5 rows x 494 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28dc83ec"
      },
      "source": [
        "## Text Feature Engineering\n",
        "\n",
        "### Subtask:\n",
        "Apply text vectorization techniques (e.g., TF-IDF) to the 'Process', 'Evaluation', and 'Planning' text columns to convert them into numerical features suitable for the regression model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52693bfc"
      },
      "source": [
        "**Reasoning**:\n",
        "To perform text feature engineering, I will import `TfidfVectorizer`, apply it to the 'Process' column, convert the result to a DataFrame, and then print the shape of the resulting TF-IDF matrix to ensure successful vectorization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f06da3b",
        "outputId": "2589b2f4-c503-41d6-b3cb-d6b89062b4be"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer_process = TfidfVectorizer()\n",
        "tfidf_process = tfidf_vectorizer_process.fit_transform(df_encoded['Process'])\n",
        "\n",
        "print(\"Shape of TF-IDF matrix for 'Process':\", tfidf_process.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of TF-IDF matrix for 'Process': (4475, 10777)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "365fd438"
      },
      "source": [
        "**Reasoning**:\n",
        "To complete the text feature engineering for the 'Process' column, I will convert the TF-IDF matrix into a DataFrame with appropriately named columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d9d9136",
        "outputId": "07392da4-796e-41c6-8e7e-7170a465f478"
      },
      "source": [
        "tfidf_process_df = pd.DataFrame(tfidf_process.toarray(), columns=[f'process_tfidf_{i}' for i in range(tfidf_process.shape[1])])\n",
        "print(\"Shape of TF-IDF DataFrame for 'Process':\", tfidf_process_df.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of TF-IDF DataFrame for 'Process': (4475, 10777)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0bc05c0"
      },
      "source": [
        "**Reasoning**:\n",
        "To continue text feature engineering, I will apply TF-IDF vectorization to the 'Evaluation' column and convert the resulting matrix into a DataFrame with specific column names.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b6485c6",
        "outputId": "406bdfea-8517-4e9b-ffe2-66c70e7df09e"
      },
      "source": [
        "tfidf_vectorizer_evaluation = TfidfVectorizer()\n",
        "tfidf_evaluation = tfidf_vectorizer_evaluation.fit_transform(df_encoded['Evaluation'])\n",
        "tfidf_evaluation_df = pd.DataFrame(tfidf_evaluation.toarray(), columns=[f'evaluation_tfidf_{i}' for i in range(tfidf_evaluation.shape[1])])\n",
        "\n",
        "print(\"Shape of TF-IDF matrix for 'Evaluation':\", tfidf_evaluation.shape)\n",
        "print(\"Shape of TF-IDF DataFrame for 'Evaluation':\", tfidf_evaluation_df.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of TF-IDF matrix for 'Evaluation': (4475, 12260)\n",
            "Shape of TF-IDF DataFrame for 'Evaluation': (4475, 12260)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa4921ac"
      },
      "source": [
        "**Reasoning**:\n",
        "To complete the text feature engineering, I will apply TF-IDF vectorization to the 'Planning' column and convert the resulting matrix into a DataFrame with specific column names.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efa33b4c",
        "outputId": "317bad18-93d6-4b6c-980f-c195f7dc6c3b"
      },
      "source": [
        "tfidf_vectorizer_planning = TfidfVectorizer()\n",
        "tfidf_planning = tfidf_vectorizer_planning.fit_transform(df_encoded['Planning'])\n",
        "tfidf_planning_df = pd.DataFrame(tfidf_planning.toarray(), columns=[f'planning_tfidf_{i}' for i in range(tfidf_planning.shape[1])])\n",
        "\n",
        "print(\"Shape of TF-IDF matrix for 'Planning':\", tfidf_planning.shape)\n",
        "print(\"Shape of TF-IDF DataFrame for 'Planning':\", tfidf_planning_df.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of TF-IDF matrix for 'Planning': (4475, 6231)\n",
            "Shape of TF-IDF DataFrame for 'Planning': (4475, 6231)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d73af15"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that all text columns have been vectorized into TF-IDF DataFrames, I will concatenate these with the `df_encoded` DataFrame and drop the original text columns ('Process', 'Evaluation', 'Planning') to create a final feature set `df_features`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f318fbb3",
        "outputId": "2cc0663d-dd16-4b6f-ed14-c634be300529"
      },
      "source": [
        "df_features = pd.concat([\n",
        "    df_encoded.drop(columns=['Process', 'Evaluation', 'Planning']),\n",
        "    tfidf_process_df,\n",
        "    tfidf_evaluation_df,\n",
        "    tfidf_planning_df\n",
        "], axis=1)\n",
        "\n",
        "print(\"Shape of the final feature DataFrame (df_features):\", df_features.shape)\n",
        "print(\"First 5 rows of df_features:\")\n",
        "print(df_features.head())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the final feature DataFrame (df_features): (4475, 29759)\n",
            "First 5 rows of df_features:\n",
            "         Session Date  Session Duration Numeric  Process Word Count  \\\n",
            "0 2018-01-15 00:00:00                        61                 116   \n",
            "1 2018-01-23 00:00:00                        46                  78   \n",
            "2 2018-01-28 00:00:00                        61                  75   \n",
            "3 2018-02-13 14:55:00                       106                 185   \n",
            "4 2018-02-18 11:40:00                        16                 215   \n",
            "\n",
            "   Evaluation Word Count  Planning Word Count  Counsellor_Daniele  \\\n",
            "0                    207                   13                True   \n",
            "1                     98                    8                True   \n",
            "2                    125                    7                True   \n",
            "3                     97                   27               False   \n",
            "4                     72                    9               False   \n",
            "\n",
            "   Counsellor_Desmond  Counsellor_Diederick  Counsellor_Etienne  \\\n",
            "0               False                 False               False   \n",
            "1               False                 False               False   \n",
            "2               False                 False               False   \n",
            "3               False                 False               False   \n",
            "4               False                 False               False   \n",
            "\n",
            "   Counsellor_Hennie  ...  planning_tfidf_6221  planning_tfidf_6222  \\\n",
            "0              False  ...                  0.0                  0.0   \n",
            "1              False  ...                  0.0                  0.0   \n",
            "2              False  ...                  0.0                  0.0   \n",
            "3              False  ...                  0.0                  0.0   \n",
            "4              False  ...                  0.0                  0.0   \n",
            "\n",
            "   planning_tfidf_6223  planning_tfidf_6224  planning_tfidf_6225  \\\n",
            "0                  0.0                  0.0                  0.0   \n",
            "1                  0.0                  0.0                  0.0   \n",
            "2                  0.0                  0.0                  0.0   \n",
            "3                  0.0                  0.0                  0.0   \n",
            "4                  0.0                  0.0                  0.0   \n",
            "\n",
            "   planning_tfidf_6226  planning_tfidf_6227  planning_tfidf_6228  \\\n",
            "0                  0.0                  0.0                  0.0   \n",
            "1                  0.0                  0.0                  0.0   \n",
            "2                  0.0                  0.0                  0.0   \n",
            "3                  0.0                  0.0                  0.0   \n",
            "4                  0.0                  0.0                  0.0   \n",
            "\n",
            "   planning_tfidf_6229  planning_tfidf_6230  \n",
            "0                  0.0                  0.0  \n",
            "1                  0.0                  0.0  \n",
            "2                  0.0                  0.0  \n",
            "3                  0.0                  0.0  \n",
            "4                  0.0                  0.0  \n",
            "\n",
            "[5 rows x 29759 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dc1b727"
      },
      "source": [
        "## Prepare Data for Modeling\n",
        "\n",
        "### Subtask:\n",
        "Combine all engineered numerical and text features, define the feature matrix (X) and the target vector (y) using 'Session Duration Numeric'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f54b0000"
      },
      "source": [
        "**Reasoning**:\n",
        "To prepare the data for modeling, I will first define the target variable 'y' as 'Session Duration Numeric' and then create the feature matrix 'X' by dropping the target and 'Session Date' columns from `df_features`, finally printing their shapes to confirm.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01b7ef3b",
        "outputId": "e9794885-57a3-45ba-917f-06cce0c274aa"
      },
      "source": [
        "y = df_features['Session Duration Numeric']\n",
        "X = df_features.drop(columns=['Session Duration Numeric', 'Session Date'])\n",
        "\n",
        "print(\"Shape of feature matrix X:\", X.shape)\n",
        "print(\"Shape of target vector y:\", y.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of feature matrix X: (4475, 29757)\n",
            "Shape of target vector y: (4475,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af32dd54"
      },
      "source": [
        "## Split Data\n",
        "\n",
        "### Subtask:\n",
        "Divide the preprocessed dataset into training and testing sets to evaluate the model's performance on unseen data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6dba514"
      },
      "source": [
        "**Reasoning**:\n",
        "To split the dataset into training and testing sets, I need to import `train_test_split` from `sklearn.model_selection` and apply it to the feature matrix `X` and target vector `y` with the specified parameters, then verify the shapes of the resulting sets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3941fe46",
        "outputId": "79559aa1-1e2d-4f0c-c137-d7928ef38f6b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (3580, 29757)\n",
            "Shape of X_test: (895, 29757)\n",
            "Shape of y_train: (3580,)\n",
            "Shape of y_test: (895,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ea7d9b7"
      },
      "source": [
        "## Model Selection and Training\n",
        "\n",
        "### Subtask:\n",
        "Select an appropriate regression model (e.g., RandomForestRegressor, GradientBoostingRegressor, or a simple Linear Regression model) and train it on the preprocessed training data. The selected model should be suitable for high-dimensional data, such as the TF-IDF features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ae8f69f"
      },
      "source": [
        "**Reasoning**:\n",
        "To select and train a regression model, I will start by importing the `Ridge` regression model from `sklearn.linear_model`, initialize it, and then fit it to the training data. Ridge regression is often a good choice for high-dimensional data like ours, as it helps prevent overfitting by penalizing large coefficients.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb63a63e",
        "outputId": "4d7c4963-2772-4d29-e5ed-e81f1209f29a"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Initialize the Ridge Regression model\n",
        "ridge_model = Ridge(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "ridge_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Ridge Regression model trained successfully.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Regression model trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c8516f4"
      },
      "source": [
        "## Model Evaluation\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the trained regression model's performance on the test set using appropriate regression metrics (e.g., Mean Absolute Error (MAE), Mean Squared Error (MSE), R-squared)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21b8e8d5"
      },
      "source": [
        "**Reasoning**:\n",
        "To evaluate the trained Ridge Regression model, I will first make predictions on the test set and then calculate key regression metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared to assess its performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "0039ec95",
        "outputId": "efdf8f38-328e-4c4d-d8be-11c03677c279"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = ridge_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False) # RMSE\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Evaluation on Test Set:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"R-squared (R2): {r2:.2f}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "got an unexpected keyword argument 'squared'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2277293979.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# RMSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;31m# Map *args/**kwargs to the function signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/inspect.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mcan\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m         \"\"\"\n\u001b[0;32m-> 3280\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbind_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/inspect.py\u001b[0m in \u001b[0;36m_bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3267\u001b[0m                 )\n\u001b[1;32m   3268\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3269\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m   3270\u001b[0m                     'got an unexpected keyword argument {arg!r}'.format(\n\u001b[1;32m   3271\u001b[0m                         arg=next(iter(kwargs))))\n",
            "\u001b[0;31mTypeError\u001b[0m: got an unexpected keyword argument 'squared'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5849ed8e"
      },
      "source": [
        "**Reasoning**:\n",
        "The error `TypeError: got an unexpected keyword argument 'squared'` indicates that the version of scikit-learn being used does not support the `squared=False` argument directly in `mean_squared_error` to calculate RMSE. To fix this, I will calculate RMSE by taking the square root of the `mse` explicitly using `np.sqrt`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3870ab75",
        "outputId": "cc132470-b979-412c-de77-6ccb4098bef4"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = ridge_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse) # Calculate RMSE by taking the square root of MSE\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Evaluation on Test Set:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"R-squared (R2): {r2:.2f}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation on Test Set:\n",
            "Mean Absolute Error (MAE): 1.77\n",
            "Mean Squared Error (MSE): 8.91\n",
            "Root Mean Squared Error (RMSE): 2.98\n",
            "R-squared (R2): 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0ce8165"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the model's performance, key insights, and suggest potential next steps for further analysis or improvement.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cb585e8"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The regression model developed to predict 'Session Duration Numeric' shows excellent performance on the test set. It achieved a Mean Absolute Error (MAE) of 1.77, a Mean Squared Error (MSE) of 8.91, a Root Mean Squared Error (RMSE) of 2.98, and a remarkably high R-squared (R2) value of 0.99.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   Missing values in the 'Process' column were successfully imputed.\n",
        "*   Categorical features ('Counsellor', 'Client', 'Phase', 'Session Duration') were one-hot encoded, significantly expanding the feature space.\n",
        "*   Text features ('Process', 'Evaluation', 'Planning') were transformed using TF-IDF vectorization, contributing to a final feature set `X` of 29,757 features for 4,475 samples.\n",
        "*   A Ridge Regression model was trained on the processed data.\n",
        "*   The model demonstrated strong predictive capabilities on the test set, achieving an R-squared of 0.99.\n",
        "*   The average prediction error was low, with a Mean Absolute Error (MAE) of 1.77 and a Root Mean Squared Error (RMSE) of 2.98.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The unusually high R-squared value of 0.99 suggests potential data leakage. It is highly probable that the encoded 'Session Duration' categorical column, used as a feature, is directly derived from or a binned version of the 'Session Duration Numeric' target variable.\n",
        "*   As a crucial next step, remove the 'Session Duration' categorical feature (and its one-hot encoded representations) from the feature set and retrain the model. This will provide a more realistic and generalizable assessment of the model's predictive performance based on other independent variables.\n"
      ]
    }
  ]
}